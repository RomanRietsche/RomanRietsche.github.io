@techreport{bauman.2020.supporting,
  title = {Supporting {{Students}} in the {{Peer-Review Process}} by {{Recommending Features}} of {{Written Feedback}} That {{Should}} Be {{Improved}}},
  author = {Bauman, Konstantin and Rietsche, Roman and S{\"o}llner, Matthias},
  year = {2020},
  month = jan,
  collaborator = {{Statistical Challenges in Electronic Commerce Research}}
}

@incollection{buholzer.2018.knowing,
  title = {Knowing What {{Learners Like}}? {{Developing}} a {{Cultural Sensitive Peer Assessment Process}} in {{MOOCs}}},
  booktitle = {Proceedings of the {{Multikonferenz Wirtschaftsinformatik}} ({{MKWI}})},
  author = {Buholzer, Fabienne and Rietsche, Roman and S{\"o}llner, Matthias},
  year = {2018},
  month = jan,
  address = {L{\"u}neburg, Germany},
  abstract = {ARRAY(0x5612905dd0f8)},
  keywords = {culture sensitive peer assessment procedure,Design science research,Higher_order_thinking_skills,Hofstede?s cultural dimension theory,Massive Open Online Courses,Rietsche},
  file = {/Users/rcr5/Zotero/storage/VD5LTM7N/Buholzer, Rietsche et al 2018 - Knowing what Learners Like.pdf}
}

@incollection{fuchs.2021.more,
  title = {Is More Always Better? {{Simulating Feedback Exchange}} in {{Organizations}}},
  booktitle = {Proceedings of the 16th {{International Conference}} on {{Wirtschaftsinformatik}} ({{WI}})},
  author = {Fuchs, Sacha and Rietsche, Roman and Aier, Stephan and Rivera, Michael},
  year = {2021},
  month = jan,
  address = {Essen, Germany},
  abstract = {ARRAY(0x556d1f573608)},
  keywords = {Digital Feedback,feedback,Organization,Rietsche,Simulation},
  file = {/Users/rcr5/Zotero/storage/IA3IX8E4/Fuchs, Rietsche et al 2021 - Is more always better.pdf}
}

@incollection{goeldi.2023.whereto,
  title = {{{WHERETO FOR AUTOMATED COACHING CONVERSATION}}: {{STRUCTURED INTERVENTION OR ADAPTIVE GENERATION}}?},
  booktitle = {In {{Proceedings}} of the 32th {{European Conference}} on {{Information Systems}} ({{ECIS}})},
  author = {Goeldi, Andreas and Rietsche, Roman},
  year = {2023},
  month = jan,
  abstract = {In an age of life-long learning, it is important that adult learners can effectively use their motivation and resources to reach their learning goals. In conversation, coaches can intervene to promote learning goal attainment by using behavioural change techniques (BCTs). In a coaching chatbot, such techniques can be ordered in an established, structured way to good effect. With recent technological advances, chatbot responses can be generated adaptively; this means that BCTs can be applied in an adaptive but less structured way. It is yet unclear whether this latter form of configuring coaching interventions is viable, how they compare to more established structured interventions, and whether both methods can be combined. For the purpose of answering this, we propose a 2x2 experimental design with the two intervention types as factors and goal attainment as the dependent variable. Results will indicate avenues for automating skilled conversation including choice of technology.},
  file = {/Users/rcr5/Zotero/storage/H87AY779/Goeldi, Rietsche 2023 - WHERETO FOR AUTOMATED COACHING CONVERSATION STRUC.pdf}
}

@techreport{goldi.2023.insertexpansions,
  title = {Insert-Expansions for {{Tool-enabled Conversational Agents}}},
  author = {G{\"o}ldi, Andreas and Rietsche, Roman},
  year = {2023},
  month = jan,
  institution = {arXiv},
  doi = {10.48550/arXiv.2307.01644},
  abstract = {This paper delves into an advanced implementation of Chain-of-Thought-Prompting in Large Language Models, focusing on the use of tools (or "plug-ins") within the explicit reasoning paths generated by this prompting method. We find that tool-enabled conversational agents often become sidetracked, as additional context from tools like search engines or calculators diverts from original user intents. To address this, we explore a concept wherein the user becomes the tool, providing necessary details and refining their requests. Through Conversation Analysis, we characterize this interaction as insert-expansion - an intermediary conversation designed to facilitate the preferred response. We explore possibilities arising from this 'user-as-a-tool' approach in two empirical studies using direct comparison, and find benefits in the recommendation domain.},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences,H.5,Human-Computer Interaction (cs.HC)},
  file = {/Users/rcr5/Zotero/storage/U44EIEZM/Göldi, Rietsche 2023 - Insert-expansions for Tool-enabled Conversational Agents.pdf}
}

@inproceedings{goldi.2024.chatbot,
  title = {Chatbot {{Agents Displaying Non-factive Reasoning Enhance Expectation Confirmation}}},
  booktitle = {International {{Conference}} on {{Information Systems}} ({{ICIS}}) 2024},
  author = {G{\"o}ldi, Andreas and Rietsche, Roman},
  year = {2024},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/EP7J5K6V/Göldi, Rietsche 2024 - Chatbot Agents Displaying Non-factive Reasoning En.pdf}
}

@inproceedings{goldi.2024.insertexpansions,
  title = {Insert-Expansions for {{Large Language Model Agents}}},
  booktitle = {Proceedings of the {{Americas Conference}} on {{Information Systems}} ({{AMCIS}}) 2024},
  author = {G{\"o}ldi, Andreas and Rietsche, Roman},
  year = {2024},
  abstract = {AI agents use language generation for internal reasoning and interacting with users. Agents often employ tools beyond language generation, such as calculators or search, to further augment these capabilities. We focus on how such tools can give the agent too much external context, diverting it from the user's original intent. According to Conversation Analysis, human-human dialogue often uses "insert-expansion" - inserted utterances for clarification - to resolve ambiguities. Building on this, we introduce a "user-as-a-tool" approach, enabling the AI agent to solicit clarification from the user while still reasoning, thereby realigning it with the user's intent. Initial evidence shows that our approach has benefits for conversational recommendation systems. We present a novel interaction method and empirical findings that enhance the user's role in guiding agent reasoning. This research is especially relevant as AI agents become increasingly common, and holds significance for optimizing the human-chatbot interaction loop.},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/2ICYNBD7/Göldi, Rietsche 2024 - Insert-expansions for Large Language Model Agents.pdf}
}

@inproceedings{goldi.2024.intelligent,
  title = {Intelligent {{Support Engages Writers Through Relevant Cognitive Processes}}},
  booktitle = {Proceedings of the {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {G{\"o}ldi, Andreas and Wambsganss, Thiemo and Neshaei, Seyed Parsa and Rietsche, Roman},
  year = {2024},
  month = may,
  pages = {1--12},
  publisher = {ACM},
  address = {Honolulu HI USA},
  doi = {10.1145/3613904.3642549},
  urldate = {2024-10-16},
  isbn = {979-8-4007-0330-0},
  langid = {english},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/HT8NACRQ/Göldi, Wambsganss 2024 - Intelligent Support Engages Writers Through Releva.pdf}
}

@inproceedings{goldi.2024.making,
  title = {Making {{Sense}} of {{Large Language Model-Based AI Agents}}},
  booktitle = {International {{Conference}} on {{Information Systems}} ({{ICIS}}) 2024},
  author = {G{\"o}ldi, Andreas and Rietsche, Roman},
  year = {2024},
  abstract = {Large Language Models (LLMs) have had major impact in society even though most LLM applications use single model calls to generate output. Recent innovations have uncovered that multiple chained calls tend to produce better results. Even more impactful is the discovery that these chains do not need to be predefined. LLM-based AI agents use frameworks to generate written intermediate reasoning that decides which steps to take next and when to return with a final output. LLM-based AI agents can use external tools like search engines, calculators, code engines, etc. to gather information and act on the world. Developments in this area are rapid and potentially consequential. However, it is difficult to keep apace with the developments. To address this, we introduce a typology grounded in recent research that provides a structured framework for understanding LLM-based agents, facilitating proactive engagement with future developments.},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/UF5ENKI2/Göldi, Rietsche 2024 - Making Sense of Large Language Model-Based AI Agen.pdf}
}

@incollection{gruettner.2020.new,
  title = {The {{New Window}} to {{Athletes}}' {{Soul}} -- {{What Social Media Tells Us About Athletes}}' {{Performances}}},
  booktitle = {Proceedings of the 53rd {{Hawaii International Conference}} on {{System Sciences}}},
  author = {Gruettner, Arne and Vitisvorakarn, Min and Wambsganss, Thiemo and Rietsche, Roman and Back, Andrea},
  editor = {Bui, Tung},
  year = {2020},
  month = jan,
  series = {Proceedings of the {{Annual Hawaii International Conference}} on {{System Sciences}}},
  publisher = {Hawaii International Conference on System Sciences},
  doi = {10.24251/HICSS.2020.303}
}

@inproceedings{guggemos.2024.measuring,
  title = {Measuring {{Computational Thinking}} - {{Developing A Short Performance Test For Higher Education}}},
  booktitle = {21st {{International Conference}} on {{Cognition}} and {{Exploratory Learning}} in {{Digital Age}} ({{CELDA}} 2024},
  author = {Guggemos, Josef and Rietsche, Roman and Strecker, Jannis Rene and Aier, Stephan and Mayer, Simon},
  year = {2024},
  abstract = {Technological advancements, particularly in artificial intelligence, significantly transform our society and work practices. Computational thinking (CT) has emerged as a crucial 21st-century skill, enabling individuals to solve problems more effectively through an automation-oriented perspective and fundamental concepts of computer science. To ensure the effective integration of CT into educational curricula, it is crucial to develop efficient assessment frameworks that allow teachers to measure and promote student CT proficiency. Therefore, our aim is to develop a short test to measure CT among undergraduate students. To this end, we consider two performance tests: the Computational Thinking test (CTt) and the Algorithmic Thinking Test for Adults (ATTA). We use items from both instruments to compile a short test. Based on a sample of 290 second-year non-computer science undergraduate students, we provide evidence on the quality of our test. Besides classical test theory, we apply item response theory, namely Rasch modeling, and confirmatory factor analysis. Our test shows favorable properties, e.g., Cronbach's alpha {$>$} .75, and may be suitable for the efficient assessment of CT across higher education programs.},
  langid = {english},
  keywords = {/unread,Assessment,Computational Thinking,Higher Education,Performance Test,Rasch-scaling}
}

@book{kopf.2015.realtime,
  title = {A Real-Time Feedback System for Presentation Skills},
  editor = {Kopf, Stephan and Sch{\"o}n, Daniel and Guthier, Benjamin and Rietsche, Roman and Effelsberg, Wolfgang},
  year = {2015},
  publisher = {Association for the Advancement of Computing in Education (AACE)},
  isbn = {1-939797-16-0},
  keywords = {Feedback_all},
  file = {/Users/rcr5/Zotero/storage/QFXPZMS2/Kopf, Schön et al (Hg) 2015 - A real-time feedback system.pdf}
}

@incollection{lechler.2019.looking,
  title = {Looking {{Beneath}} the {{Tip}} of the {{Iceberg}}: {{The Two-Sided Nature}} of {{Chatbots}} and Their {{Roles}} for {{Digital Feedback Exchange}}},
  author = {Lechler, Ruth and St{\"o}ckli, Emanuel and Rietsche, Roman and Uebernickel, Falk},
  year = {2019},
  month = jan,
  publisher = {Proceedings of the European Conference on Information Systems (ECIS)},
  address = {Stockholm, Sweden},
  keywords = {Feedback_all,Rietsche},
  file = {/Users/rcr5/Zotero/storage/YX5IKXCM/Lechler, Stöckli et al 2019 - Looking Beneath the Tip.pdf}
}

@inproceedings{meier.2024.ai,
  title = {An {{AI Approach}} for {{Predicting Audience Reach}} of {{Presentation Slides}}},
  booktitle = {Proceeding of the {{European Conference}} on {{Information Systems}} ({{ECIS}}) 2024},
  author = {Meier, Alexander and Rietsche, Roman and Blohm, Ivo},
  year = {2024},
  abstract = {There is a near overflow of presentation slides on digital platforms, such as SlideShare.net, with 40 million. This presents a challenge in assessing their projected impact due to its high complexity and required expertise. We propose a novel approach using machine learning techniques to predict presentation slide audience reach. We crawled a unique dataset of over 8000 slides and extracted relevant attributes. A model was trained where we are the first to employ both numerical and textual inputs. Initial results with an R{$^2$} value of 0.579 suggest that the audience reach of presentation slides can be automatically evaluated. Our findings contribute to the current understanding of the assessment of online documents, introducing possibilities for further research, such as focusing on domain-specific applications and incorporating them as tools for decision support in content management systems on sharing platforms.},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/ISHNADI7/Meier, Rietsche 2024 - An AI Approach for Predicting Audience Reach of Pr.pdf}
}

@inproceedings{meier.2024.assisted,
  title = {Towards {{Assisted Excellence}}: {{Designing}} an {{AI-Based}}  {{System}} for {{Presentation Slide Evaluation}}},
  booktitle = {19th {{International Conference}} on {{Design Science Research}} in {{Information Systems}} and {{Technology}}, ({{DESRIST}}) 2024},
  author = {Meier, Alexander and Rietsche, Roman and Blohm, Ivo},
  year = {2024},
  abstract = {Creating and disseminating high-quality presentation slides have be come a foundation for effective communication in educational, corporate, and  scientific domains. This study addresses the challenge of enhancing the quality  of user-generated presentation content amidst the vast quantities of existing re sources. The study is concerned with an ongoing design science research project  that focuses on constructing a nascent design theory for a novel AI-based slide  evaluation support system (SESS) that aims to assist users, particularly educators,  create high-quality presentation slides. The proposed concept leverages recent  developments in Generative Artificial Intelligence (genAI) to analyze multi modal user-generated content. Drawing on signaling theory, user-generated  online reviews, and expert interviews, this research aims to contribute to deline ating the capabilities of artificial intelligence in digital content evaluation, spe cifically in assisting users to improve the quality of their presentation slides. For  practitioners, we offer a set of generalized design principles and design features  for the implementation in the development of an AI-based SESS.},
  langid = {american},
  keywords = {/unread,Design Science Research,Generative AI,Presentation Slides},
  file = {/Users/rcr5/Zotero/storage/CEFMTNZM/Meier, Rietsche 2024 - Towards Assisted Excellence Designing an AI-Based.pdf}
}

@inproceedings{neshaei.2024.enhancing,
  title = {Enhancing {{Peer Review}} with {{AI-Powered Suggestion Generation Assistance}}: {{Investigating}} the {{Design Dynamics}}},
  shorttitle = {Enhancing {{Peer Review}} with {{AI-Powered Suggestion Generation Assistance}}},
  booktitle = {Proceedings of the 29th {{International Conference}} on {{Intelligent User Interfaces}}},
  author = {Neshaei, Seyed Parsa and Rietsche, Roman and Su, Xiaotian and Wambsganss, Thiemo},
  year = {2024},
  month = mar,
  pages = {88--102},
  publisher = {ACM},
  address = {Greenville SC USA},
  doi = {10.1145/3640543.3645169},
  urldate = {2025-01-21},
  abstract = {While writing peer reviews resembles an important task in science, education, and large organizations, providing fruitful suggestions to peers is not a straightforward task, as different user interaction designs of text suggestion interfaces can have diverse effects on user behaviors when writing the review text. Generative language models might be able to support humans in formulating reviews with textual suggestions. Previous systems use two designs for providing text suggestions, but do not empirically evaluate them: inline and list of suggestions. To investigate the effects of embedding NLP text generation models in the two designs, we collected user requirements to implement Hamta as an example of assistants providing reviewers with text suggestions. Our experiment on comparing the two designs on 31 participants indicates that people using the inline interface provided longer reviews on average, while participants using the list of suggestions experienced more ease of use in using our tool. The results shed light on important design findings for embedding text generation models in user-centered assistants.},
  isbn = {979-8-4007-0508-3},
  langid = {english},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/YGPL6TG6/Neshaei, Rietsche 2024 - Enhancing Peer Review with AI-Powered Suggestion G.pdf}
}

@incollection{rietsche.2011.creation,
  title = {Creation of an {{Online Virtual Cisco Router Learning Environment}}},
  booktitle = {Proceedings of the 14th {{IASTED}} International Conference on {{Computers}} and Advanced Technology in Education, {{July}} 11 - 13, 2011, {{Cambridge}}, {{UK}}},
  author = {Rietsche, Roman and Russell, Gordon and Karduck, Achim P.},
  editor = {Uskov, V.},
  year = {2011},
  month = jan,
  publisher = {s. n.]},
  address = {[S. l.},
  doi = {10.2316/P.2011.734-045},
  isbn = {978-0-88986-888-5},
  keywords = {Rietsche},
  file = {/Users/rcr5/Zotero/storage/S8NPIZ4L/Rietsche, Russell et al 2011 - Creation of an Online Virtual.pdf}
}

@incollection{rietsche.2017.digital,
  title = {Digital Formative Learning Assessment Tool - {{Towards}} Helping Students to Take Ownership of Their Learning},
  booktitle = {Proceedings of the {{European Conference}} on {{Information Systems}} ({{ECIS}})},
  author = {Rietsche, Roman and S{\"o}llner, Matthias and Seufert, Sabine},
  year = {2017},
  month = jan,
  address = {Guimar{\~a}es, Portugal},
  abstract = {ARRAY(0x561290849238)},
  keywords = {action design research,Digital formative learning assessment,feedback,HIGHER education,large-scale class,Rietsche},
  file = {/Users/rcr5/Zotero/storage/T5IMCMKT/Rietsche, Söllner et al 2017 - Digital formative learning assessment tool.pdf}
}

@article{rietsche.2017.obvious,
  title = {The Obvious and Hidden Values of {{IT-based}} Peer Assessment in Management Education},
  author = {Rietsche, Roman and S{\"o}llner, Matthias},
  year = {2017},
  month = jan,
  journal = {Paper presented at the Academy of Management Annual Meeting (AOM). Atlanta, Georgia, USA.},
  abstract = {ARRAY(0x5612905d8560)},
  keywords = {feedback,IT-based peer assessment,large-scale class,management education,Rietsche,Technology-Mediated Learning},
  file = {/Users/rcr5/Zotero/storage/8FEPPDS6/Rietsche, Söllner 2017 - The obvious and hidden values.pdf}
}

@incollection{rietsche.2017.twofold,
  title = {The {{Twofold Value}} of {{IT-Based Peer Assessment}} in {{Management Information Systems Education}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Wirtschaftsinformatik}} ({{WI}})},
  author = {Rietsche, Roman and Lehmann, Katja and Haas, Philipp and S{\"o}llner, Matthias},
  year = {2017},
  month = jan,
  address = {St Gallen, Switzerland},
  abstract = {ARRAY(0x7f2a44f6cd58)},
  keywords = {feedback,higher-education,IT-based peer assessment,large-scale class,Rietsche,Technology-Mediated Learning},
  file = {/Users/rcr5/Zotero/storage/PCTLGE4A/Rietsche, Lehmann et al 2017 - The Twofold Value of IT-Based.pdf}
}

@inproceedings{rietsche.2018.design,
  title = {Design and {{Evaluation}} of an {{IT-based Formative Feedback Tool}} to {{Foster Student Performance}}},
  booktitle = {Proceedings of the {{International Conference}} on {{Information Systems}} ({{ICIS}})},
  author = {Rietsche, Roman and Duss, Kevin and Persch, Jan Martin and Soellner, Matthias},
  year = {2018},
  address = {San Francisco, CA, USA},
  keywords = {Feedback_all,Higher_order_thinking_skills,Rietsche},
  file = {/Users/rcr5/Zotero/storage/6BXHNDCX/Rietsche, Duss et al 2018 - Design and Evaluation.pdf}
}

@incollection{rietsche.2019.insights,
  title = {Insights on {{Using IT-Based Peer Feedback}} to {{Practice}} the {{Students Providing Feedback Skill}}},
  booktitle = {Hawaii {{International Conference}} on {{System Sciences}} ({{HICSS}})},
  author = {Rietsche, Roman and S{\"o}llner, Matthias},
  year = {2019},
  month = jan,
  address = {Maui, Hawaii, USA}
}


@incollection{rietsche.2019.not,
  title = {Not All {{Reviews}} Are {{Equal}} - a {{Literature Review}} on {{Online Review Helpfulness}}},
  booktitle = {Proceedings of the 27th {{European Conference}} on {{Information Systems}} ({{ECIS}})},
  author = {Rietsche, Roman and Frei, Daniel and Stoeckli, Emanuel and Soellner, Matthias},
  year = {2019},
  month = jan,
  keywords = {Rietsche},
  file = {/Users/rcr5/Zotero/storage/ULZPUP8V/Rietsche, Frei et al 2019 - Not all Reviews are Equal.pdf}
}

@phdthesis{rietsche.2020.enhancing,
  title = {Enhancing {{Student Performance Through Technology-Mediated Formative Feedback}} in {{Large Scale University Lectures}}},
  author = {Rietsche, Roman},
  year = {2020},
  month = jan,
  keywords = {Rietsche},
  file = {/Users/rcr5/Zotero/storage/EDWSZQJR/Rietsche 2020 - Enhancing Student Performance Through Technology-Mediated.pdf}
}

@incollection{rietsche.2020.impact,
  title = {The Impact of Practice on Feedback-Providing Skills in an Online Peer Review Activity},
  booktitle = {Handbook of {{Teaching}} with {{Technology}} in {{Management}}, {{Leadership}}, and {{Business}}},
  author = {Rietsche, Roman and S{\"o}llner, Matthias and Leimeister, Jan Marco},
  editor = {Allen, Stuart and Gower, Kim and Allen, Danielle K.},
  year = {2020},
  month = jan,
  publisher = {Edward Elgar Publishing},
  doi = {10.4337/9781789901658.00047},
  isbn = {978-1-78990-165-8}
}

@incollection{rietsche.2021.does,
  title = {Does {{Real-Time Feedback Matter}}? {{A Simulation Study}} to {{Link Individual}} and {{Organizational Performance}}},
  booktitle = {Workshop on {{Information Technologies}} and {{Systems}} ({{WITS}}) in Conjunction with the 42nd {{International Conference}} on {{Information Systems}} ({{ICIS}})},
  author = {Rietsche, Roman and Aier, Stephan and Rivera, Michael},
  year = {2021},
  month = jan,
  address = {Virtual Conference}
}

@article{rietsche.2021.quantum,
  title = {Quantum {{Computing}}: {{Der Traum}} Vom {{Mehr}}},
  author = {Rietsche, Roman and Dremel, Christian},
  year = {2021},
  month = jan,
  journal = {Ada},
  file = {/Users/rcr5/Zotero/storage/Y75U4TIP/Rietsche, Dremel 2021 - Quantum Computing.pdf}
}

@incollection{rietsche.2022.corpus,
  title = {A {{Corpus}} for {{Suggestion Mining}} of {{German Peer Feedback}}},
  booktitle = {Proceedings of the {{Language Resources}} and {{Evaluation Conference}}},
  author = {Rietsche, Roman and Ritz, Eva and Janda, Julius and Pf{\"u}tze, Dominik},
  year = {2022},
  month = jan,
  pages = {55395547},
  publisher = {European Language Resources Association},
  address = {Marseille, France},
  doi = {June},
  abstract = {Peer feedback in online education becomes increasingly important to meet the demand for feedback in large scale classes, such as e.g. Massive Open Online Courses (MOOCs). However, students are often not experts in how to write helpful feedback to their fellow students. In this paper, we introduce a corpus compiled from university students' peer feedback to be able to detect suggestions on how to improve the students' work and therefore being able to capture peer feedback helpfulness. To the best of our knowledge, this corpus is the first student peer feedback corpus in German which additionally was labelled with a new annotation scheme. The corpus consists of more than 600 written feedback (about 7,500 sentences). The utilisation of the corpus is broadly ranged from Dependency Parsing to Sentiment Analysis to Suggestion Mining, etc. We applied the latter to empirically validate the utility of the new corpus. Suggestion Mining is the extraction of sentences that contain suggestions from unstructured text. In this paper, we present a new annotation scheme to label sentences for Suggestion Mining. Two independent annotators labelled the corpus and achieved an inter-annotator agreement of 0.71. With the help of an expert arbitrator a gold standard was created. An automatic classification using BERT achieved an accuracy of 75.3\%.}
}

@article{rietsche.2022.quantum,
  title = {Quantum Computing},
  author = {Rietsche, Roman and Dremel, Christian and Bosch, Samuel and Steinacker, L{\'e}a and Meckel, Miriam and Leimeister, Jan-Marco},
  year = {2022},
  month = jan,
  journal = {Electronic Markets},
  volume = {32},
  number = {4},
  pages = {2525--2536},
  issn = {1019-6781},
  doi = {10.1007/s12525-022-00570-y},
  file = {/Users/rcr5/Zotero/storage/ZYEHRD2U/Rietsche, Dremel et al 2022 - Quantum computing.pdf}
}

@incollection{rietsche.2022.specificity,
  title = {The {{Specificity}} and {{Helpfulness}} of {{Peer-to-Peer Feedback}} in {{Higher Education}}},
  booktitle = {Proceedings of the 17th {{Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}} ({{BEA}} 2022)},
  author = {Rietsche, Roman and Caines, Andrew and Schramm, Cornelius and Pf{\"u}tze, Dominik and Buttery, Paula},
  year = {2022},
  month = jan,
  pages = {107117},
  publisher = {Association for Computational Linguistics},
  address = {Seattle, Washington},
  abstract = {With the growth of online learning through MOOCs and other educational applications, it has become increasingly difficult for course providers to offer personalized feedback to students. Therefore asking students to provide feedback to each other has become one way to support learning. This peer-to-peer feedback has become increasingly important whether in MOOCs to provide feedback to thousands of students or in large-scale classes at universities. One of the challenges when allowing peer-to-peer feedback is that the feedback should be perceived as helpful, and an import factor determining helpfulness is how specific the feedback is. However, in classes including thousands of students, instructors do not have the resources to check the specificity of every piece of feedback between students. Therefore, we present an automatic classification model to measure sentence specificity in written feedback. The model was trained and tested on student feedback texts written in German where sentences have been labelled as general or specific. We find that we can automatically classify the sentences with an accuracy of 76.7\% using a conventional feature-based approach, whereas transfer learning with BERT for German gives a classification accuracy of 81.1\%. However, the feature-based approach comes with lower computational costs and preserves human interpretability of the coefficients. In addition we show that specificity of sentences in feedback texts has a weak positive correlation with perceptions of helpfulness. This indicates that specificity is one of the ingredients of good feedback, and invites further investigation.}
}

@incollection{ritz.2022.unleashing,
  title = {Unleashing {{Process Mining}} for {{Education}}: {{Designing}} an {{IT-Tool}} for {{Students}} to {{Self-Monitor}} Their {{Personal Learning Paths}}},
  booktitle = {Proceedings of the 17th {{Internationale Tagung Wirtschaftsinformatik}} ({{WI}})},
  author = {Ritz, Eva and Wambsganss, Thiemo and Rietsche, Roman and Schmitt, Anuschka and {Oeste-Rei{\ss}}, Sarah and Leimeister, Jan Marco},
  year = {2022},
  month = jan,
  address = {N{\"u}rnberg (Online), Germany},
  keywords = {Educational Process Mining}
}

@inproceedings{ritz.2023.artificial,
  title = {Artificial {{Socialization}}? {{How Artificial Intelligence Applications Can Shape A New Era}} of {{Employee Onboarding Practices}}},
  shorttitle = {Artificial {{Socialization}}?},
  booktitle = {Hawaii {{International Conference}} on {{System Sciences}}},
  author = {Ritz, Eva and Donisi, Fabio and Elshan, Edona and Rietsche, Roman},
  year = {2023},
  doi = {10.24251/HICSS.2023.020},
  urldate = {2024-08-02},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/8MUXBUAT/Ritz, Donisi 2023 - Artificial Socialization How Artificial Intellige.pdf}
}

@article{ritz.2023.how,
  title = {How to {{Support Students}}' {{Self-Regulated Learning}} in {{Times}} of {{Crisis}}: {{An Embedded Technology-Based Intervention}} in {{Blended Learning Pedagogies}}},
  author = {Ritz, Eva and Rietsche, Roman and Leimeister, Jan Marco},
  year = {2023},
  month = jan,
  journal = {Academy of Management Learning \& Education},
  volume = {22},
  number = {3},
  pages = {357--382},
  issn = {1537-260X},
  doi = {10.5465/amle.2022.0188}
}

@article{ritz.2024.how,
  title = {How a {{Swiss}} Luxury Retailer Implements Process Mining to Improve Data-Driven Customer Excellence},
  author = {Ritz, Eva and Joas, Adrian and Wambsganss, Thiemo and Rietsche, Roman and Leimeister, Jan Marco},
  year = {2024},
  month = jun,
  journal = {Journal of Information Technology Teaching Cases},
  pages = {20438869241261399},
  issn = {2043-8869, 2043-8869},
  doi = {10.1177/20438869241261399},
  urldate = {2024-10-16},
  abstract = {In today's digital transformation era, process mining has emerged as a crucial technology, playing an integral part in the digital strategies of many organizations. Despite its significance, implementing process mining to leverage data-driven decision-making and boosting process efficiency presents notable challenges for such companies. This case study delves into the journey of the fictitious Swiss luxury retailer Elysian as they utilize process mining to derive data-driven insights on process inefficiencies and bottlenecks to increase their customer excellence for online retail procurement. The case highlights the capabilities of process mining for organizations. It is among the first to offer students hands-on guidance on process discovery, conformance, and enhancement using real-world data. Students take the role of Lisa Dister, Head of procurement in the business unit home care, who urgently requires improving process transparency after an unsatisfying internal audit result. This immersive experience helps students understand the application of process mining in high-volume data scenarios and equips them with skills in data literacy. Moreover, students are challenged to suggest recommendations for long-term process optimization and reflect on the effectiveness of process mining for tackling procurement issues.},
  langid = {english},
  keywords = {/unread}
}

@inproceedings{ritz.2024.what,
  title = {What to {{Learn Next}}? {{Designing Personalized Learning Paths}} for {{Re-}}\&{{Upskilling}} in {{Organizations}}},
  booktitle = {Proceedings of the 56th {{Hawaii International Conference}} on {{System Sciences}} ({{HICSS}}) 2024},
  author = {Ritz, Eva and Freise, Leonie and Elshan, Edona and Rietsche, Roman and Bretschneider, Ulrich},
  year = {2024},
  address = {Waikiki, Hawaii, USA},
  abstract = {The fast-paced acceleration of digitalization requires extensive re-\&upskilling, impacting a significant proportion of jobs worldwide. Technology-mediated learning platforms have become instrumental in addressing these efforts, as they can analyze platform data to provide personalized learning journeys. Such personalization is expected to increase employees' empowerment, job satisfaction, and learning outcomes. However, the challenge lies in efficiently deploying these opportunities using novel technologies, prompting questions about the design and analysis of generating personalized learning paths in organizational learning. We, therefore, analyze and classify recent research on personalized learning paths into four major concepts (learning context, data, interface, and adaptation) with ten dimensions and 34 characteristics. Six expert interviews validate the taxonomy's use and outline three exemplary use cases, undermining its feasibility. Information Systems researchers can use our taxonomy to develop theoretical models to study the effectiveness of personalized learning paths in intra-organizational re-\&upskilling.},
  keywords = {skill_profile},
  file = {/Users/rcr5/Zotero/storage/3DJYD3G6/Ritz, Freise 2024 - What to Learn Next Designing Personalized Learnin.pdf}
}

@article{seufert.2019.pedagogical,
  title = {A {{Pedagogical Perspective}} on {{Big Data}} and {{Learning Analytics}}: {{A Conceptual Model}} for {{Digital Learning Support}}},
  author = {Seufert, Sabine and Meier, Christoph and Soellner, Matthias and Rietsche, Roman},
  year = {2019},
  journal = {Technology, Knowledge and Learning},
  volume = {24},
  number = {4},
  pages = {599--619},
  issn = {2211-1662},
  doi = {10.1007/s10758-019-09399-5},
  keywords = {Rietsche},
  file = {/Users/rcr5/Zotero/storage/3WNVXUDW/Seufert, Meier et al 2019 - A Pedagogical Perspective on Big.pdf}
}

@article{sollner.2021.individualisierung,
  title = {Individualisierung in Der Beruflichen {{Bildung}} Durch {{Hybrid Intelligence}}. {{Potentiale}} Und {{Grenzen}}},
  author = {S{\"o}llner, Matthias and Janson, Andreas and Rietsche, Roman and {Thiel de Gafenco}, Marian},
  editor = {Seufert, Sabine and Guggemos, Josef and Ifenthaler, Dirk and Ertl, Hubert and Seifried, J{\"u}rgen},
  year = {2021},
  month = jan,
  journal = {Zeitschrift f{\"u}r Berufs- und Wirtschaftsp{\"a}dagogik},
  volume = {Beiheft 31},
  pages = {163--181},
  publisher = {Zeitschrift f{\"u}r Berufs- und Wirtschaftsp{\"a}dagogik},
  keywords = {Hybrid Intelligence}
}

@incollection{su.2023.reviewriter,
  title = {Reviewriter: {{AI-Generated Instructions For Peer Review Writing}}},
  booktitle = {Proceedings of the 18th {{Workshop}} on {{Innovative Use}} of {{NLP}} for {{Building Educational Applications}} ({{BEA}} 2023)},
  author = {Su, Xiaotian and Wambsganss, Thiemo and Rietsche, Roman and Neshaei, Seyed Parsa and Kser, Tanja},
  year = {2023},
  month = jan,
  pages = {57--71},
  publisher = {Association for Computational Linguistics},
  address = {Stroudsburg, PA, USA},
  doi = {10.18653/v1/2023.bea-1.5}
}

@incollection{wambsganss.2019.designing,
  title = {Towards {{Designing}} an {{Adaptive Argumentation Learning Tool}}},
  booktitle = {International {{Conference}} on {{Information Systems}} ({{ICIS}})},
  author = {Wambsganss, Thiemo and Rietsche, Roman},
  year = {2019},
  month = jan,
  address = {Munich, Germany},
  keywords = {Rietsche}
}

@inproceedings{wambsganss.2022.bias,
  title = {Bias at a {{Second Glance}}: {{A Deep Dive}} into {{Bias}} for {{German Educational Peer-Review Data Modeling}}},
  booktitle = {Proceedings of the 29th {{International Conference}} on {{Computational Linguistics}} ({{COLING}}) 2022},
  author = {Wambsganss, Thiemo and Swamy, Vinitra and Rietsche, Roman and K{\"a}ser, Tanja},
  year = {2022},
  pages = {1344--1356},
  abstract = {Natural Language Processing (NLP) has become increasingly utilized to provide adaptivity in educational applications. However, recent research has highlighted a variety of biases in pre-trained language models. While existing studies investigate bias in different domains, they are limited in addressing fine-grained analysis on educational and multilingual corpora. In this work, we analyze bias across text and through multiple architectures on a corpus of 9,165 German peer-reviews collected from university students over five years. Notably, our corpus includes labels such as helpfulness, quality, and critical aspect ratings from the peer-review recipient as well as demographic attributes. We conduct a Word Embedding Association Test (WEAT) analysis on (1) our collected corpus in connection with the clustered labels, (2) the most common pre-trained German language models (T5, BERT, and GPT-2) and GloVe embeddings, and (3) the language models after fine-tuning on our collected data-set. In contrast to our initial expectations, we found that our collected corpus does not reveal many biases in the co-occurrence analysis or in the GloVe embeddings. However, the pre-trained German language models find substantial conceptual, racial, and gender bias and have significant changes in bias across conceptual and racial axes during fine-tuning on the peer-review data. With our research, we aim to contribute to the fourth UN sustainability goal (quality education) with a novel dataset, an understanding of biases in natural language education data, and the potential harms of not counteracting biases in language models for educational tasks.},
  keywords = {/unread},
  file = {/Users/rcr5/Zotero/storage/WVWUHRE2/Wambsganss, Swamy 2022 - Bias at a Second Glance A Deep Dive into Bias for.pdf}
}

@incollection{wambsganss.2023.unraveling,
  title = {Unraveling {{Downstream Gender Bias}} from {{Large Language Models}}: {{A Study}} on {{AI Educational Writing Assistance}}},
  booktitle = {Proceedings of the {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}}) {{Conference}}},
  author = {Wambsganss, Thiemo and Su, Xiaotian and Swamy, Vinitra and Neshaei, Seyed Parsa and Rietsche, Roman and K{\"a}ser, Tanja},
  year = {2023},
  month = jan,
  doi = {10.48550/arXiv.2311.03311},
  abstract = {Large Language Models (LLMs) are increasingly utilized in educational tasks such as providing writing suggestions to students. Despite their potential, LLMs are known to harbor inherent biases which may negatively impact learners. Previous studies have investigated bias in models and data representations separately, neglecting the potential impact of LLM bias on human writing. In this paper, we investigate how bias transfers through an AI writing support pipeline. We conduct a large-scale user study with 231 students writing business case peer reviews in German. Students are divided into five groups with different levels of writing support: one classroom group with feature-based suggestions and four groups recruited from Prolific -- a control group with no assistance, two groups with suggestions from fine-tuned GPT-2 and GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and Sentence Embedding Association Test (SEAT) we evaluate the gender bias at various stages of the pipeline: in model embeddings, in suggestions generated by the models, and in reviews written by students. Our results demonstrate that there is no significant difference in gender bias between the resulting peer reviews of groups with and without LLM suggestions. Our research is therefore optimistic about the use of AI writing support in the classroom, showcasing a context where bias in LLMs does not transfer to students' responses.  Accepted as a full paper at EMNLP Findings 2023}
}
